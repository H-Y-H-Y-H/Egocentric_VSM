# Egocentric Visual Self-Modeling for Autonomous Robot Dynamics Prediction and Adaptation (Under Review)

This repository contains the supplementary materials for the paper "Egocentric Visual Self-Modeling for Autonomous Robot Dynamics Prediction and Adaptation".


## Repository Structure
- `supplementary_materials.pdf`: Contains the source code for the egocentric visual self-model and related experiments
- `code/`: Contains the source code for the egocentric visual self-model and related experiments
  - `simulation/`: Code for running experiments in simulation
  - `real_world/`: Code for running experiments on real-world robots
- `data/`: Contains the datasets used in the experiments
  - `simulation/`: Datasets for simulation experiments
  - `real_world/`: Datasets for real-world experiments
- `models/`: Pre-trained models for the egocentric visual self-model
- `figures/`: Figures and visualizations used in the paper
- `videos/`: Supplementary videos demonstrating the experiments

## Requirements
- [List the main dependencies and their versions]

## Usage
1. Clone the repository.
2. Install the required dependencies
3. [Provide instructions on how to run the code and reproduce the experiments]
